services:
  zookeeper:
    image: "bitnami/zookeeper:latest"
    # image: docker.io/bitnami/zookeeper:3.8
    container_name: zookeeper
    networks:
      - localnet
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    restart: unless-stopped

  kafka:
    image: "bitnami/kafka:latest"
    # image: docker.io/bitnami/kafka:3.3
    container_name: kafka
    networks:
      - localnet
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    depends_on:
      - zookeeper
    restart: unless-stopped    

  elasticsearch:
    image: elasticsearch:7.17.6
    container_name: elasticsearch
    environment:
      - ELASTIC_PASSWORD=changeme
      - xpack.security.enabled=true
      - xpack.security.authc.api_key.enabled=true
      - discovery.type=single-node
      - cluster.name=es-docker
      - node.name=node1
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    # mem_limit: 4g
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - localnet
    restart: unless-stopped

  mongo:
    image: mongo:latest
    container_name: mongo
    restart: always
    entrypoint: [ "/usr/bin/mongod", "--bind_ip_all", "--replSet", "rs0" ]
    volumes:
      - ./mongo-scripts/rs-init.sh:/scripts/rs-init.sh
      - ./mongo-scripts/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin
    ports:
      - "27017:27017"
    networks:
      - localnet
    # command: [ "bash", "mongosh --file /scripts/rs-init.sh && mongosh --file /docker-entrypoint-initdb.d/mongo-init.js" ]

    
  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - localnet
    restart: always

  starrock:
    image: starrocks/allin1-ubuntu
    container_name: starrock
    restart: always
    ports:
    - "9030:9030" 
    - "8030:8030"
    - "8040:8040"
    healthcheck:
      test: 'mysql -u root -h starrock -P 9030 -e "show frontends\G" |grep "Alive: true"'
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - localnet

  # kafka-connect:
  #   image: confluentinc/cp-kafka-connect:latest
  #   container_name: kafka-connect
  #   depends_on:
  #     - kafka
  #     - starrock
  #   networks:
  #   - localnet
  #   volumes:
  #     - ./kafka-config:/etc/kafka-connect
  #   environment:
  #     CONNECT_BOOTSTRAP_SERVERS: kafka:9092
  #     CONNECT_REST_PORT: 8083
  #     CONNECT_GROUP_ID: connect-group
  #     CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
  #     CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
  #     CONNECT_STATUS_STORAGE_TOPIC: connect-status
  #     CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
  #     CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
  #     CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
  #     CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
  #   command:
  #     - connect-standalone
  #     - /etc/kafka-connect/connect-standalone.properties
  #     - /etc/kafka-connect/connect-StarRocks-sink.properties
  

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.2.0
    container_name: kafka-connect
    depends_on:
      - kafka
      - starrock
    networks:
      - localnet
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
    command:
      - connect-standalone
      - /etc/kafka-connect/connect-standalone.properties
      - /etc/kafka-connect/connect-StarRocks-sink.properties
  

  kafka-connect-v2:
    image: confluentinc/cp-kafka-connect:latest
    container_name: kafka-connect
    depends_on:
      - kafka
      - starrock
    networks:
    - localnet
    command: 
      - bash
      - -c
      - "connect-standalone /etc/kafka-connect/connect-standalone.properties /etc/kafka-connect/connect-StarRocks-sink.properties"
    volumes:
      - ./starrocks-kafka-connector-1.0.4:/usr/share/confluent-hub-components/starrocks-kafka-connector
      - ./config/connect-standalone.properties:/etc/kafka-connect/connect-standalone.properties
      - ./config/connect-StarRocks-sink.properties:/etc/kafka-connect/connect-StarRocks-sink.properties
    environment:
      CONNECT_CLASSPATH: "/usr/share/confluent-hub-components/starrocks-kafka-connector/*"


  # kibana:
  #   container_name: kibana
  #   image: kibana:7.17.6
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #     - ELASTICSEARCH_USERNAME=elastic
  #     - ELASTICSEARCH_PASSWORD=changeme
  #   ports:
  #     - 5601:5601
  #   networks:
  #     - test
  #   depends_on:
  #     - elasticsearch

  monstache-profile:
    # image: rwynn/monstache:6.7.10
    image: monstache_profile
    container_name: monstache_profile
    working_dir: /app
    command: -f ./streaming_elasticsearch.config.toml
    volumes:
      - ./streaming_elasticsearch.config.toml:/app/streaming_elasticsearch.config.toml
    environment:
      - INDEX_MAPPING=mobio-profiling-v16_3
    depends_on:
      - elasticsearch
      - mongo
    ports:
      - "8080:8080"
    networks:
      - localnet
    healthcheck:
      test: "wget -q -O - http://localhost:8080/healthz"
      interval: 10s
      timeout: 30s
      retries: 300
    restart: unless-stopped

  spark:
    image: apache/spark
    container_name: spark
    networks:
      - localnet
    restart: unless-stopped
    # volumes:
    #   - ./spark-apps:/opt/spark-apps  # Thư mục chứa ứng dụng Scala của bạn
    #   - ./spark-jars:/opt/spark/jars  # Thư mục chứa các JAR connector
    environment:
      - SPARK_MODE=master           # Chạy Spark ở chế độ master
      - SPARK_MASTER_HOST=spark     # Đặt host cho Spark master
      - SPARK_MASTER_PORT=7077      # Port mặc định của Spark master
    ports:
      - "8081:8081"                 # Web UI của Spark master
      - "7077:7077"                 # Port giao tiếp Spark master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master  # Khởi động Spark master
    
  # monstache-tags:
  #   image: rwynn/monstache:6.7.10
  #   container_name: monstachetags
  #   working_dir: /app
  #   command: -f ./monstache_tags.config.toml
  #   volumes:
  #     - ./monstache_tags.config.toml:/app/monstache_tags.config.toml
  #   depends_on:
  #     - elasticsearch
  #     - mongo0
  #   ports:
  #     - "8081:8080"
  #   networks:
  #     - test
  #   healthcheck:
  #     test: "wget -q -O - http://localhost:8080/healthz"
  #     interval: 10s
  #     timeout: 30s
  #     retries: 300
  #   restart: unless-stopped

volumes:
  elasticsearch-data:
    driver: local

networks:
  localnet:
    driver: bridge