H∆∞·ªõng D·∫´n Thi·∫øt L·∫≠p H·ªá Th·ªëng Pipeline D·ªØ Li·ªáu v·ªõi MongoDB, StarRocks & Elasticsearch
1. Gi·ªõi Thi·ªáu

T√†i li·ªáu n√†y h∆∞·ªõng d·∫´n c√°ch thi·∫øt l·∫≠p h·ªá th·ªëng pipeline d·ªØ li·ªáu v·ªõi MongoDB l√†m ngu·ªìn d·ªØ li·ªáu ch√≠nh, s·ª≠ d·ª•ng Monstache ƒë·ªÉ streaming d·ªØ li·ªáu, PySpark ƒë·ªÉ x·ª≠ l√Ω batch, v√† t√≠ch h·ª£p Elasticsearch v√† StarRocks ƒë·ªÉ l∆∞u tr·ªØ v√† ph√¢n t√≠ch d·ªØ li·ªáu. Ngo√†i ra, h·ªá th·ªëng c≈©ng bao g·ªìm Prometheus + Grafana ƒë·ªÉ gi√°m s√°t.
2. C√°c Th√†nh Ph·∫ßn C·∫ßn C√†i ƒê·∫∑t
2.1. C∆° s·ªü d·ªØ li·ªáu & L∆∞u tr·ªØ

‚úÖ MongoDB ‚Üí L∆∞u tr·ªØ d·ªØ li·ªáu g·ªëc.
‚úÖ StarRocks ‚Üí L∆∞u tr·ªØ d·ªØ li·ªáu ph√¢n t√≠ch.
‚úÖ Elasticsearch ‚Üí L∆∞u tr·ªØ d·ªØ li·ªáu ph·ª•c v·ª• t√¨m ki·∫øm nhanh.
2.2. Streaming & Batch Processing

‚úÖ Monstache ‚Üí Streaming d·ªØ li·ªáu t·ª´ MongoDB ‚Üí Elasticsearch & StarRocks.
‚úÖ PySpark ‚Üí Batch processing d·ªØ li·ªáu t·ª´ MongoDB l√™n Elasticsearch & StarRocks.
2.3. Gi√°m s√°t h·ªá th·ªëng

‚úÖ Prometheus + Grafana ‚Üí Gi√°m s√°t hi·ªáu su·∫•t h·ªá th·ªëng v√† d·ªØ li·ªáu.
‚úÖ Loki (tu·ª≥ ch·ªçn) ‚Üí Logging t·∫≠p trung cho monitoring.
2.4. C√¥ng c·ª• h·ªó tr·ª£ kh√°c

‚úÖ Docker ‚Üí ƒê·ªÉ ch·∫°y t·∫•t c·∫£ c√°c th√†nh ph·∫ßn trong container.

B∆∞·ªõc 3: Truy c·∫≠p v√†o MongoDB Shell trong container:

N·∫øu MongoDB kh√¥ng kh·ªüi t·∫°o ƒë∆∞·ª£c cluster b·∫±ng script rs-init.sh, kh·ªüi t·∫°o th·ªß c√¥ng b·∫±ng c√°ch sau:
```bash
$ docker-compose exec mongo bash
$ sh scripts/rs-init.sh
```

N·∫øu MongoDB kh√¥ng kh·ªüi t·∫°o ƒë∆∞·ª£c user, s·ª≠ d·ª•ng c√°c command line sau ƒë√¢y ƒë·ªÉ kh·ªüi t·∫°o:
```bash
$ docker-compose exec mongo mongosh
$ use admin
$ db.createUser({user: "admin", pwd: "admin",roles:[{role: "userAdminAnyDatabase" , db:"admin"}]}) 
# docker-entrypoint-initdb.d/mongo-init.js
use local

    Ki·ªÉm tra Oplog:

db.oplog.rs.find().limit(5).pretty()

N·∫øu th·∫•y d·ªØ li·ªáu, Oplog ƒë√£ ho·∫°t ƒë·ªông th√†nh c√¥ng.

4. Thi·∫øt L·∫≠p Monstache ƒë·ªÉ ƒê·ªìng B·ªô MongoDB ‚Üí StarRocks & Elasticsearch (x·ª≠ l√Ω Streaming)
    4.1 ƒê·ªìng b·ªô elasticsearch
        4.1.1 t·∫°o image monstache c√° nh√¢n
        Do m√¥i tr∆∞·ªùng ·ªü local v√† m√¥i tr∆∞·ªùng trong docker l√† kh√°c nhau n√™n n·∫øu build file .so ·ªü local r·ªìi mount v√†o docker th√¨ trong docker kh√¥ng ƒë·ªçc ƒë∆∞·ª£c.
        ch·∫°y file dockerfile ƒë·ªÉ t·∫°o ri√™ng 1 images: docker build -t monstache_profile 
        K·∫øt qu·∫£: c√≥ file some_cases_plugin.go trong th∆∞ m·ª•c bin/profiling c·ªßa container_name: monstacheprofile

        Thay image v·ª´a build ƒë∆∞·ª£c t·ª´ Dockerfile v√†o image c·ªßa Monstache

        ƒê·ªÉ s·ª≠ d·ª•ng plugin ·ªü nhi·ªÅu n∆°i kh√°c nhau th√¨ copy file .so v·ª´a build v·ªÅ local v√† g·ª≠i cho team devops ƒë·ªÉ ƒë·∫©y l√™n c√°c m√°y: 
            docker cp <CONTAINER ID>:/bin/profiling/some_cases_plugin.so /<path>/some_cases_plugin.so

        4.1.2  Run l·∫°i ƒë·ªÉ mount file so
            C√≥ 2 c√°ch l√† th√™m command mapper-plugin-path file .so c·ªßa images monstache, ho·∫∑c th√™m key "mapper-plugin-path" trong file toml r·ªìi ch·∫°y l·∫°i images
            -c√°ch 1: file docker-compose
            monstache-profile:
                image: monstache_profile:latest
                container_name: monstacheprofile
                working_dir: /app
                command: -f ./streaming_elasticsearch.config.toml -mapper-plugin-path /bin/profiling/some_cases_plugin.so
                volumes:
                - ./streaming_elasticsearch.config.toml:/app/streaming_elasticsearch.config.toml
            -c√°ch 2: file toml
            stats = true
            resume = true
            resume-strategy = 1
            resume-name="monstache-profiling-profile"

            mapper-plugin-path = "/bin/profiling/plugin_profile.so"

            [logs]
            error = "/dev/stderr"

        4.1.3 Ki·ªÉm tra c√≥ ƒë·ªìng b·ªô ƒë∆∞·ª£c kh√¥ng
    4.2 ƒê·ªìng b·ªô Starrock
        Monstache s·∫Ω ƒë·ªçc d·ªØ li·ªáu t·ª´ MongoDB b·∫±ng Change Streams ho·∫∑c Direct Read, sau ƒë√≥ g·ª≠i d·ªØ li·ªáu l√™n StarRocks b·∫±ng HTTP Stream Load API.

        üîó Lu·ªìng d·ªØ li·ªáu:
        MongoDB ‚ûù Monstache ‚ûù HTTP Stream Load API ‚ûù StarRocks
        üîó C·∫•p full quy·ªÅn truy c·∫≠p v√† thao t√°c cho user root:
        docker exec -it starrock mysql -h127.0.0.1 -P9030 -uroot
        SHOW GRANTS FOR 'root'@'%';
        GRANT ALL PRIVILEGES ON *.* TO 'root'@'%';
        GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;
        üîó T·∫°o 1 user v√† c·∫•p quy·ªÅn:
        mysql -h 127.0.0.1 -P 9030 -u root
        mysql> CREATE USER 'toandd'@'%' IDENTIFIED BY '123';
        GRANT SYSTEM ALL TO toan WITH GRANT OPTION;

        Query OK, 0 rows affected (0,01 sec)
        # c·∫ßn vi·∫øt l·∫°i doc xem c·∫•p quy·ªÅn c√°i n√†o l√† ƒë√∫ng
        GRANT root TO 'toan';
        GRANT db_admin TO 'toan';
        GRANT cluster_admin TO 'toan';
        GRANT user_admin TO 'toan';
        SET DEFAULT ROLE ALL TO 'toan';

        mysql> GRANT ALL PRIVILEGES ON *.* TO 'toandd'@'%' WITH GRANT OPTION;
        GRANT ALL ON *.* TO 'toan'@'%' WITH GRANT OPTION;

        GRANT GRANT OPTION ON SYSTEM TO 'toandd'@'%';

        mysql -h 127.0.0.1 -P 9030 -u toandd -p
        CREATE DATABASE profiling;
        SHOW DATABASES;
        USE profiling;
        CREATE TABLE profile (
            id INT,
            name VARCHAR(50),
            age INT,
            email VARCHAR(100)
        )
        ENGINE=OLAP
        DUPLICATE KEY(id)
        DISTRIBUTED BY HASH(id) BUCKETS 3
        PROPERTIES ("replication_num" = "1");

        1. T·∫°o th∆∞ m·ª•c l√†m vi·ªác
            mkdir ~/Documents/pipeline_mongo/kafka-config
            cd ~/Documents/pipeline_mongo/kafka-config
        2. T·∫£i file starrocks-kafka-connector-1.0.4.tar.gz
        wget https://github.com/StarRocks/starrocks-connector-for-kafka/releases/download/v1.0.4/starrocks-kafka-connector-1.0.4.tar.gz
        tar -xzf starrocks-kafka-connector-1.0.4.tar.gz
        cd starrocks-connector-for-kafka-1.0.4

        sua file pom.xml phan build
    #     <build>
    #     <plugins>
    #         <plugin>
    #             <groupId>org.apache.maven.plugins</groupId>
    #             <artifactId>maven-shade-plugin</artifactId>
    #             <version>3.4.1</version>
    #             <executions>
    #                 <execution>
    #                     <phase>package</phase>
    #                     <goals>
    #                         <goal>shade</goal>
    #                     </goals>
    #                     <configuration>
    #                         <createDependencyReducedPom>false</createDependencyReducedPom>
    #                         <filters>
    #                             <filter>
    #                                 <artifact>*:*</artifact>
    #                                 <excludes>
    #                                     <exclude>META-INF/*.SF</exclude>
    #                                     <exclude>META-INF/*.DSA</exclude>
    #                                     <exclude>META-INF/*.RSA</exclude>
    #                                 </excludes>
    #                             </filter>
    #                         </filters>
    #                     </configuration>
    #                 </execution>
    #             </executions>
    #         </plugin>
    #     </plugins>
    # </build>
        sudo apt install maven
        mvn clean package
        sau khi xong th√¨ ƒë·∫£m b·∫£o ch·ªâ c√≤n 3 file trong th∆∞ m·ª•c:
        connect-standalone.properties
        connect-StarRocks-sink.properties
        starrocks-connector-for-kafka-1.0-SNAPSHOT.jar (hi·ªán t·∫°i sau khi maven th√¨ th√†nh snapshot)
        ch·∫°y l·∫°i docker kafka-connect
5. C√†i ƒê·∫∑t PySpark ƒë·ªÉ X·ª≠ L√Ω Batch
B∆∞·ªõc 1: C√†i ƒê·∫∑t PySpark

(TBD)
B∆∞·ªõc 2: Batch Processing l√™n Elasticsearch & StarRocks

(TBD)
6. C√†i ƒê·∫∑t Prometheus + Grafana ƒë·ªÉ Gi√°m S√°t

(TBD)
7. Ki·ªÉm Tra & Debug

(TBD)
8. K·∫øt Lu·∫≠n

Sau khi th·ª±c hi·ªán c√°c b∆∞·ªõc tr√™n, b·∫°n s·∫Ω c√≥ m·ªôt h·ªá th·ªëng MongoDB ch·∫°y Replica Set, Monstache ƒë·ªìng b·ªô d·ªØ li·ªáu sang StarRocks v√† Elasticsearch, PySpark x·ª≠ l√Ω batch l√™n c·∫£ hai, v√† Prometheus + Grafana gi√°m s√°t h·ªá th·ªëng. C√°c b∆∞·ªõc ti·∫øp theo s·∫Ω t·∫≠p trung v√†o t·ªëi ∆∞u v√† m·ªü r·ªông h·ªá th·ªëng.


